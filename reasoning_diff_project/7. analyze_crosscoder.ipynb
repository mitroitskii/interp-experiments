{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "# ??? do i need these?\n",
    "%autoreload 2\n",
    "from dictionary_learning import CrossCoder # local copy of github.com/mitroitskii/dictionary_learning\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "th.set_grad_enabled(False)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # [ ] maybe import stuff via this - eg science_of_finetuning. etc; gotta change .. though\n",
    "\n",
    "# [ ] figure out which imports are needed and in which order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# [ ] fix up the args\n",
    "\n",
    "# crosscoder_path = \"/share/u/troitskiid/projects/interp-experiments/reasoning_diff_project/checkpoints/L15_mu3.6e-02_lr1e-04_20250305_010218/L15_mu3.6e-02_lr1e-04.pt\"\n",
    "# crosscoder = \"L15_mu3.6e-02_lr1e-04\"\n",
    "# crosscoder_path = \"/share/u/troitskiid/projects/interp-experiments/reasoning_diff_project/checkpoints/L20-mu3.6e-02-lr1e-04_20250304_163255/L20-mu3.6e-02-lr1e-04.pt\"\n",
    "# crosscoder = \"L20-mu3.6e-02-lr1e-04\"\n",
    "crosscoder_path = \"/share/u/troitskiid/projects/interp-experiments/reasoning_diff_project/checkpoints/L25_mu3.6e-02_lr1e-04_20250305_010218/L25_mu3.6e-02_lr1e-04.pt\"\n",
    "crosscoder = \"L25_mu3.6e-02_lr1e-04\"\n",
    "extra_args = []\n",
    "exp_name = \"eval_crosscoder\"\n",
    "exp_id = \"\"\n",
    "device = \"cuda\"\n",
    "base_layer = 0\n",
    "reasoning_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "\n",
    "coder = CrossCoder.from_pretrained(crosscoder_path)\n",
    "num_layers, activation_dim, dict_size = coder.encoder.weight.shape\n",
    "print(coder)\n",
    "\n",
    "save_path = (\n",
    "    Path(\"./analysis\") / exp_name / (crosscoder + (f\"_{exp_id}\" if exp_id else \"\"))\n",
    ")\n",
    "if save_path.exists():\n",
    "    save_path = Path(str(save_path) + \"_new\")\n",
    "    if save_path.exists():\n",
    "        warnings.warn(f\"Folder {save_path} already exists, and was removed\")\n",
    "        rmtree(save_path)\n",
    "save_path_extra = save_path / \"extra\"\n",
    "save_path_extra.mkdir(exist_ok=True, parents=True)\n",
    "save_path_html = save_path / \"html\"\n",
    "save_path_html.mkdir(exist_ok=False)\n",
    "save_path_data = save_path / \"data\"\n",
    "save_path_data.mkdir(exist_ok=False)\n",
    "if device == \"auto\":\n",
    "    device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = th.device(device)\n",
    "all_info = {}\n",
    "feature_df = {k: {} for k in range(dict_size)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Latent analysis on test set -->\n",
    "\n",
    "# NOTE: not using this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.add_activation_stats:\n",
    "#     stats_path = Path(f\"../stats/{crosscoder}\")\n",
    "#     fw_stats = th.load(stats_path / \"fineweb.pt\").rescaled.joint\n",
    "#     lmsys_stats = th.load(stats_path / \"lmsys.pt\").rescaled.joint\n",
    "#     fw_deads = (fw_stats.non_zero_counts == 0).cpu()\n",
    "#     fw_avg_activations = (\n",
    "#         fw_stats.avg_activation\n",
    "#         * fw_stats.total_tokens\n",
    "#         / fw_stats.non_zero_counts.float()\n",
    "#     ).cpu()\n",
    "#     fw_freqs = (fw_stats.non_zero_counts.float() / fw_stats.total_tokens).cpu()\n",
    "#     lmsys_deads = (lmsys_stats.non_zero_counts == 0).cpu()\n",
    "#     lmsys_avg_activations = (\n",
    "#         (\n",
    "#             lmsys_stats.avg_activation\n",
    "#             * lmsys_stats.total_tokens\n",
    "#             / lmsys_stats.non_zero_counts.float()\n",
    "#         ).cpu()\n",
    "#     ).cpu()\n",
    "#     lmsys_freqs = (lmsys_stats.non_zero_counts.float() / lmsys_stats.total_tokens).cpu()\n",
    "#     freqs = (\n",
    "#         (fw_stats.non_zero_counts + lmsys_stats.non_zero_counts).float()\n",
    "#         / (fw_stats.total_tokens + lmsys_stats.total_tokens).float()\n",
    "#     ).cpu()\n",
    "#     deads = fw_deads & lmsys_deads\n",
    "#     avg_activations = (\n",
    "#         fw_avg_activations * fw_stats.non_zero_counts.cpu()\n",
    "#         + lmsys_avg_activations * lmsys_stats.non_zero_counts.cpu()\n",
    "#     ).float() / (fw_stats.non_zero_counts + lmsys_stats.non_zero_counts).float().cpu()\n",
    "\n",
    "#     for f_idx, (\n",
    "#         fw_dead,\n",
    "#         fw_freq,\n",
    "#         lmsys_dead,\n",
    "#         lmsys_freq,\n",
    "#         freq,\n",
    "#         dead,\n",
    "#         avg_activation,\n",
    "#         lmsys_avg_activation,\n",
    "#         fw_avg_activation,\n",
    "#     ) in enumerate(\n",
    "#         zip(\n",
    "#             fw_deads,\n",
    "#             fw_freqs,\n",
    "#             lmsys_deads,\n",
    "#             lmsys_freqs,\n",
    "#             freqs,\n",
    "#             deads,\n",
    "#             avg_activations,\n",
    "#             lmsys_avg_activations,\n",
    "#             fw_avg_activations,\n",
    "#         )\n",
    "#     ):\n",
    "#         feature_df[f_idx][\"fw_dead\"] = fw_dead.item()\n",
    "#         feature_df[f_idx][\"fw_freq\"] = fw_freq.item()\n",
    "#         feature_df[f_idx][\"lmsys_dead\"] = lmsys_dead.item()\n",
    "#         feature_df[f_idx][\"lmsys_freq\"] = lmsys_freq.item()\n",
    "#         feature_df[f_idx][\"freq\"] = freq.item()\n",
    "#         feature_df[f_idx][\"dead\"] = dead.item()\n",
    "#         feature_df[f_idx][\"avg_activation\"] = avg_activation.item()\n",
    "#         feature_df[f_idx][\"lmsys_avg_activation\"] = lmsys_avg_activation.item()\n",
    "#         feature_df[f_idx][\"fw_avg_activation\"] = fw_avg_activation.item()\n",
    "\n",
    "#     print(f\"frac of dead features: {deads.float().mean().item()}\")\n",
    "#     th.save(deads, save_path_data / \"deads.pt\")\n",
    "# else:\n",
    "#     deads = th.zeros(dict_size, dtype=bool)\n",
    "# alive_mask = ~deads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare feature norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deads = th.zeros(dict_size, dtype=bool)\n",
    "alive_mask = ~deads\n",
    "\n",
    "norms = coder.decoder.weight.norm(dim=-1)\n",
    "norm_diffs = (\n",
    "    (norms[base_layer] - norms[reasoning_layer]) / norms.max(dim=0).values + 1\n",
    ") / 2\n",
    "norm_diffs = norm_diffs.cpu()\n",
    "for f_idx, (base_norm, reasoning_norm, norm_diff) in enumerate(\n",
    "    zip(norms[base_layer], norms[reasoning_layer], norm_diffs)\n",
    "):\n",
    "    feature_df[f_idx][\"dec_base_norm\"] = base_norm.item()\n",
    "    feature_df[f_idx][\"dec_reasoning_norm\"] = reasoning_norm.item()\n",
    "    feature_df[f_idx][\"dec_norm_diff\"] = norm_diff.item()\n",
    "\n",
    "# Create color array based on norm difference categories\n",
    "colors = [\n",
    "    (\n",
    "        \"green\"\n",
    "        if x <= 0.1\n",
    "        else \"orange\" if x >= 0.9 else \"blue\" if 0.4 <= x <= 0.6 else \"grey\"\n",
    "    )\n",
    "    for x in norm_diffs[alive_mask]\n",
    "]\n",
    "\n",
    "# Create masks for each category\n",
    "reasoning_only_mask = norm_diffs[alive_mask] <= 0.1\n",
    "base_only_mask = norm_diffs[alive_mask] >= 0.9\n",
    "shared_mask = (0.4 <= norm_diffs[alive_mask]) & (norm_diffs[alive_mask] <= 0.6)\n",
    "other_mask = ~(reasoning_only_mask | base_only_mask | shared_mask)\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add histogram traces for each category\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=norm_diffs[alive_mask][reasoning_only_mask],\n",
    "        name=\"Reasoning only\",\n",
    "        marker_color=\"green\",\n",
    "        nbinsx=50,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=norm_diffs[alive_mask][base_only_mask],\n",
    "        name=\"Base only\",\n",
    "        marker_color=\"orange\",\n",
    "        nbinsx=50,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=norm_diffs[alive_mask][shared_mask],\n",
    "        name=\"Shared\",\n",
    "        marker_color=\"blue\",\n",
    "        nbinsx=50,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=norm_diffs[alive_mask][other_mask],\n",
    "        name=\"Other\",\n",
    "        marker_color=\"grey\",\n",
    "        nbinsx=50,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=0,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"  <b>(Reasoning only)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "            font=dict(color=\"green\"),\n",
    "        ),\n",
    "        dict(\n",
    "            x=0.5,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"    <b>(shared)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "            font=dict(color=\"blue\"),\n",
    "        ),\n",
    "        dict(\n",
    "            x=1,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"  <b>(Base only)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "            font=dict(color=\"orange\"),\n",
    "        ),\n",
    "    ],\n",
    "    shapes=[\n",
    "        dict(\n",
    "            type=\"line\",\n",
    "            x0=0.1,\n",
    "            y0=0,\n",
    "            x1=0.1,\n",
    "            y1=1,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            line=dict(color=\"green\", width=2),\n",
    "        ),\n",
    "        dict(\n",
    "            type=\"line\",\n",
    "            x0=0.9,\n",
    "            y0=0,\n",
    "            x1=0.9,\n",
    "            y1=1,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            line=dict(color=\"orange\", width=2),\n",
    "        ),\n",
    "        dict(\n",
    "            type=\"line\",\n",
    "            x0=0.4,\n",
    "            y0=0,\n",
    "            x1=0.4,\n",
    "            y1=1,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            line=dict(color=\"blue\", width=2),\n",
    "        ),\n",
    "        dict(\n",
    "            type=\"line\",\n",
    "            x0=0.6,\n",
    "            y0=0,\n",
    "            x1=0.6,\n",
    "            y1=1,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            line=dict(color=\"blue\", width=2),\n",
    "        ),\n",
    "    ],\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.update_xaxes(tickvals=[0, 0.5, 1])\n",
    "# fig.update_traces(hovertemplate='Feature Index: %{text}<br>Value: %{y}', text=sorted_norm_diffs.indices)\n",
    "fig.update_xaxes(title=f\"Sorted Features (Highest to Lowest Difference) for {crosscoder}\")\n",
    "fig.update_yaxes(title=\"Relative Decoder Feature Norm Difference\")\n",
    "fig.update_layout(barmode=\"stack\")\n",
    "fig.show()\n",
    "fig.write_html(save_path_html / \"decoder_norm_diffs.html\")\n",
    "fig.write_image(save_path / \"decoder_norm_diffs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    x=norm_diffs[deads],\n",
    "    title=\"Relative difference in decoder dead feature norms\",\n",
    "    orientation=\"v\",\n",
    "    nbins=50,\n",
    ")\n",
    "fig.update_layout(\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=0,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"  <b>(Reasoning only)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "        ),\n",
    "        dict(\n",
    "            x=0.5,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"    <b>(shared)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "        ),\n",
    "        dict(\n",
    "            x=1,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"  <b>(Base only)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "fig.update_xaxes(tickvals=[0, 0.5, 1])\n",
    "# fig.update_traces(hovertemplate='Feature Index: %{text}<br>Value: %{y}', text=sorted_norm_diffs.indices)\n",
    "fig.update_xaxes(title=\"Sorted Features (Highest to Lowest Difference)\")\n",
    "fig.update_yaxes(title=\"Relative Norm Difference\")\n",
    "fig.show()\n",
    "fig.write_html(save_path_html / \"decoder_norm_diffs_dead.html\")\n",
    "fig.write_image(save_path_extra / \"decoder_norm_diffs_dead.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Chat only and base only feature index\n",
    "treshold = 0.1\n",
    "only_reasoning_feature_indices = th.nonzero(norm_diffs < treshold, as_tuple=True)[0]\n",
    "only_base_feature_indices = th.nonzero(norm_diffs > 1 - treshold, as_tuple=True)[0]\n",
    "shared_feature_indices = th.nonzero((norm_diffs - 0.5).abs() < treshold, as_tuple=True)[\n",
    "    0\n",
    "]\n",
    "\n",
    "th.save(only_reasoning_feature_indices, save_path_data / \"only_reasoning_decoder_feature_indices.pt\")\n",
    "th.save(\n",
    "    only_base_feature_indices, save_path_data / \"only_base_decoder_feature_indices.pt\"\n",
    ")\n",
    "th.save(shared_feature_indices, save_path_data / \"shared_decoder_feature_indices.pt\")\n",
    "all_info[\"frac of dead Reasoning only features\"] = (\n",
    "    deads[only_reasoning_feature_indices].float().mean().item()\n",
    ")\n",
    "all_info[\"frac of dead base only features\"] = (\n",
    "    deads[only_base_feature_indices].float().mean().item()\n",
    ")\n",
    "all_info[\"frac of dead shared features\"] = (\n",
    "    deads[shared_feature_indices].float().mean().item()\n",
    ")\n",
    "is_other_feature = th.ones_like(deads, dtype=bool)\n",
    "is_other_feature[only_reasoning_feature_indices] = False\n",
    "is_other_feature[only_base_feature_indices] = False\n",
    "is_other_feature[shared_feature_indices] = False\n",
    "all_info[\"frac of dead other features\"] = deads[is_other_feature].float().mean().item()\n",
    "\n",
    "for f_idx in only_reasoning_feature_indices.tolist():\n",
    "    feature_df[f_idx][\"tag\"] = \"Reasoning only\"\n",
    "for f_idx in only_base_feature_indices.tolist():\n",
    "    feature_df[f_idx][\"tag\"] = \"Base only\"\n",
    "for f_idx in shared_feature_indices.tolist():\n",
    "    feature_df[f_idx][\"tag\"] = \"Shared\"\n",
    "for f_idx in is_other_feature.nonzero(as_tuple=True)[0].tolist():\n",
    "    feature_df[f_idx][\"tag\"] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_norms = coder.encoder.weight.norm(dim=1)\n",
    "enc_norm_diffs = (\n",
    "    (enc_norms[base_layer] - enc_norms[reasoning_layer]) / enc_norms.max(dim=0).values\n",
    "    + 1\n",
    ") / 2\n",
    "enc_norm_diffs = enc_norm_diffs.cpu()\n",
    "\n",
    "for f_idx, (base_norm, reasoning_norm, norm_diff) in enumerate(\n",
    "    zip(enc_norms[base_layer], enc_norms[reasoning_layer], enc_norm_diffs)\n",
    "):\n",
    "    feature_df[f_idx][\"enc_base_norm\"] = base_norm.item()\n",
    "    feature_df[f_idx][\"enc_reasoning_norm\"] = reasoning_norm.item()\n",
    "    feature_df[f_idx][\"enc_norm_diff\"] = norm_diff.item()\n",
    "\n",
    "fig = px.histogram(\n",
    "    x=enc_norm_diffs[alive_mask],\n",
    "    title=\"Relative difference in encoder alive feature norms\",\n",
    "    orientation=\"v\",\n",
    "    nbins=50,\n",
    ")\n",
    "fig.update_xaxes(title=\"Relative Norm Difference\")\n",
    "fig.update_yaxes(title=\"Count\")\n",
    "fig.update_layout(\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=0,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"<b>(Reasoning only)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "        ),\n",
    "        dict(\n",
    "            x=0.5,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"<b>(shared)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "        ),\n",
    "        dict(\n",
    "            x=1,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"<b>(Base only)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(save_path_html / \"encoder_norm_diffs.html\")\n",
    "fig.write_image(save_path / \"encoder_norm_diffs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_norms = coder.encoder.weight.norm(dim=1)\n",
    "enc_norm_diffs = (\n",
    "    (enc_norms[base_layer] - enc_norms[reasoning_layer]) / enc_norms.max(dim=0).values\n",
    "    + 1\n",
    ") / 2\n",
    "\n",
    "for f_idx, (base_norm, reasoning_norm, norm_diff) in enumerate(\n",
    "    zip(enc_norms[base_layer], enc_norms[reasoning_layer], enc_norm_diffs)\n",
    "):\n",
    "    feature_df[f_idx][\"enc_base_norm\"] = base_norm.item()\n",
    "    feature_df[f_idx][\"enc_reasoning_norm\"] = reasoning_norm.item()\n",
    "    feature_df[f_idx][\"enc_norm_diff\"] = norm_diff.item()\n",
    "\n",
    "fig = px.histogram(\n",
    "    x=enc_norm_diffs[deads],\n",
    "    title=\"Relative difference in encoder dead feature norms\",\n",
    "    orientation=\"v\",\n",
    "    nbins=50,\n",
    ")\n",
    "fig.update_xaxes(title=\"Relative Norm Difference\")\n",
    "fig.update_yaxes(title=\"Count\")\n",
    "fig.update_layout(\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=0,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"<b>(Reasoning only)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "        ),\n",
    "        dict(\n",
    "            x=0.5,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"<b>(shared)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "        ),\n",
    "        dict(\n",
    "            x=1,\n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"<b>(Base only)</b>\",\n",
    "            showarrow=False,\n",
    "            yanchor=\"top\",\n",
    "            xanchor=\"left\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(save_path_html / \"encoder_norm_diffs_dead.html\")\n",
    "fig.write_image(save_path_extra / \"encoder_norm_diffs_dead.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cos_sims = cosine_similarity(\n",
    "    coder.decoder.weight[base_layer], coder.decoder.weight[reasoning_layer], dim=1\n",
    ")\n",
    "for f_idx, cos_sim in enumerate(decoder_cos_sims):\n",
    "    feature_df[f_idx][\"dec_cos_sim\"] = cos_sim.item()\n",
    "\n",
    "decoder_cos_sims_sorted = decoder_cos_sims.sort(descending=True)\n",
    "\n",
    "# Calculate mean cosine similarity between random latent vectors\n",
    "num_samples = 10000\n",
    "random_idx = th.randint(0, coder.decoder.weight.shape[1], (num_samples, 2))\n",
    "random_cos_sims = cosine_similarity(\n",
    "    coder.decoder.weight[base_layer][random_idx[:, 0]],\n",
    "    coder.decoder.weight[reasoning_layer][random_idx[:, 1]],\n",
    "    dim=1,\n",
    ")\n",
    "mean_random_cos_sim = random_cos_sims.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    x=decoder_cos_sims[alive_mask].cpu(),\n",
    "    title=\"Cosine similarity between decoder alive feature vectors\",\n",
    "    orientation=\"v\",\n",
    "    nbins=50,\n",
    ")\n",
    "fig.update_xaxes(title=\"Cosine Similarity\")\n",
    "fig.update_yaxes(title=\"Count\")\n",
    "fig.add_vline(\n",
    "    x=mean_random_cos_sim,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"red\",\n",
    "    annotation_text=f\"Mean Random Cosine Similarity: {mean_random_cos_sim:.4f}\",\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(save_path_html / \"decoder_cos_sims.html\")\n",
    "fig.write_image(save_path / \"decoder_cos_sims.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(feature_df).T\n",
    "\n",
    "filtered_decoder_cos_sims = decoder_cos_sims[alive_mask].cpu()\n",
    "filtered_tags = df[\"tag\"][alive_mask.cpu().numpy()]\n",
    "\n",
    "# Normalize by amount of each tag that are not dead\n",
    "tag_counts = filtered_tags.value_counts()\n",
    "\n",
    "# Create histogram with normalized counts\n",
    "fig = px.histogram(\n",
    "    x=filtered_decoder_cos_sims,\n",
    "    title=\"Cosine similarity between decoder feature vectors (Alive)\",\n",
    "    orientation=\"v\",\n",
    "    nbins=50,\n",
    "    color=filtered_tags,\n",
    "    color_discrete_map={\n",
    "        \"Shared\": \"blue\",\n",
    "        \"Base only\": \"orange\",\n",
    "        \"Reasoning only\": \"green\",\n",
    "        \"Other\": \"grey\",\n",
    "    },\n",
    "    # Normalize histogram counts by tag frequency\n",
    "    histnorm=\"probability\",\n",
    "    # Group by tag to normalize each category separately\n",
    "    barmode=\"group\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title=\"Cosine Similarity\")\n",
    "fig.update_yaxes(title=\"Normalized Count\", range=[0, 1])\n",
    "fig.add_vline(\n",
    "    x=mean_random_cos_sim,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"red\",\n",
    "    annotation_text=f\"Mean Random Cosine Similarity: {mean_random_cos_sim:.4f}\",\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(save_path_html / \"decoder_cos_sims_colored.html\")\n",
    "fig.write_image(save_path / \"decoder_cos_sims_colored.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    x=decoder_cos_sims[deads],\n",
    "    title=\"Cosine similarity between decoder dead feature vectors\",\n",
    "    orientation=\"v\",\n",
    "    nbins=50,\n",
    ")\n",
    "fig.update_xaxes(title=\"Cosine Similarity\")\n",
    "fig.update_yaxes(title=\"Count\")\n",
    "fig.add_vline(\n",
    "    x=mean_random_cos_sim,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"red\",\n",
    "    annotation_text=f\"Mean Random Cosine Similarity: {mean_random_cos_sim:.4f}\",\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(save_path_html / \"decoder_cos_sims_dead.html\")\n",
    "fig.write_image(save_path_extra / \"decoder_cos_sims_dead.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cos_sims = cosine_similarity(\n",
    "    coder.encoder.weight[base_layer], coder.encoder.weight[reasoning_layer], dim=0\n",
    ")\n",
    "for f_idx, cos_sim in enumerate(encoder_cos_sims):\n",
    "    feature_df[f_idx][\"enc_cos_sim\"] = cos_sim.item()\n",
    "\n",
    "mean_random_cos_sim_encoder = (\n",
    "    cosine_similarity(\n",
    "        coder.encoder.weight[base_layer][:, random_idx[:, 0]],\n",
    "        coder.encoder.weight[reasoning_layer][:, random_idx[:, 1]],\n",
    "        dim=0,\n",
    "    )\n",
    "    .mean()\n",
    "    .item()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    x=encoder_cos_sims[alive_mask].cpu(),\n",
    "    title=\"Cosine similarity between encoder alive feature vectors\",\n",
    "    orientation=\"v\",\n",
    "    nbins=50,\n",
    ")\n",
    "fig.update_xaxes(title=\"Cosine Similarity\")\n",
    "fig.update_yaxes(title=\"Count\")\n",
    "fig.add_vline(\n",
    "    x=mean_random_cos_sim_encoder,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"red\",\n",
    "    annotation_text=f\"Mean Random Cosine Similarity: {mean_random_cos_sim_encoder:.4f}\",\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(save_path_html / \"encoder_cos_sims.html\")\n",
    "fig.write_image(save_path / \"encoder_cos_sims.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    x=encoder_cos_sims[deads],\n",
    "    title=\"Cosine similarity between encoder dead feature vectors\",\n",
    "    orientation=\"v\",\n",
    "    nbins=50,\n",
    ")\n",
    "fig.update_xaxes(title=\"Cosine Similarity\")\n",
    "fig.update_yaxes(title=\"Count\")\n",
    "fig.add_vline(\n",
    "    x=mean_random_cos_sim_encoder,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"red\",\n",
    "    annotation_text=f\"Mean Random Cosine Similarity: {mean_random_cos_sim_encoder:.4f}\",\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(save_path_html / \"encoder_cos_sims_dead.html\")\n",
    "fig.write_image(save_path_extra / \"encoder_cos_sims_dead.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "pd.DataFrame(feature_df).T.to_csv(save_path_data / \"feature_df.csv\")\n",
    "with open(save_path_data / \"all_info.json\", \"w\") as f:\n",
    "    json.dump(all_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if stem ends with  _new\n",
    "# rm the old folder\n",
    "# remove _new from name\n",
    "# Check if the save_path stem ends with '_new'\n",
    "if str(save_path).endswith(\"_new\"):\n",
    "    # Remove the old folder\n",
    "    old_folder = Path(str(save_path).removesuffix(\"_new\"))  # Remove '_new' from the end\n",
    "    if old_folder.exists():\n",
    "        rmtree(old_folder)\n",
    "\n",
    "    # Rename the new folder by removing '_new'\n",
    "    save_path.rename(old_folder)\n",
    "    save_path = old_folder  # Update the save_path variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(feature_df).T\n",
    "display(df.sort_values(by=\"dec_norm_diff\", ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
